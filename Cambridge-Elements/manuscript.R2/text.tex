
\section{Introduction}

%\rev{TODO do we need to any additional refs?}

Phylogenetic inference, \rev{also known as phylogenetic tree inference or simply tree inference}, is common in all facets of biology and estimating a phylogeny is a critical step in many comparative analyses. The fact that tree inference is common can obscure the underlying complexity of the task.
When a researcher estimates a phylogeny, they are attempting to reconstruct evolutionary events that potentially occurred millions of years ago.
In modern phylogenetics, \rev{inferring} trees is often achieved \rev{by} using an evolutionary model \rev{that} ideally captures the generating processes that underlie our data.
Since no two datasets are exactly the same, in terms of evolutionary history or \rev{taxon} sampling, choosing the best approach to build a phylogeny requires deep knowledge of the taxonomic group, as well as phylogenetic theory.
In this review, we focus on the models commonly used to infer phylogenies in macroevolution and paleobiology research.

The primary source of evidence used to infer evolutionary relationships are phylogenetic characters: molecular sequences \rev{and morphology} in the case of living species or morphology in the case of most fossils.
The number of differences observed between \rev{the species included in the phylogeny} are used to measure evolutionary distances and to group \rev{them} together in the tree.
%This estimation becomes more challenging if we also need to estimate dated phylogenies.
\rev{This task, however, becomes more challenging if we also need to date the inferred phylogenies.}
%This is because phylogenetic characters only contain information about \textit{relative} time.
%Additional temporal evidence is required to calibrate trees to \textit{absolute} time.
This is because phylogenetic characters only contain information \rev{about how fast or how slow species evolve depending on the measured evolutionary distance, which is \textit{relative} time.  Additional temporal evidence, which can be given by geological events or the fossil record, is required to calibrate trees to geological time (sometimes called \textit{absolute} time).} %\strikethough{also} 
Otherwise, it is not straightforward to distinguish between rapid evolutionary rates over short intervals versus slow evolutionary rates over long intervals.
Fig. \ref{fig:undated} provides a recap of the most important features of a phylogeny (tips, nodes, and branches, which together comprise the \rev{tree} topology) and shows an example of the output generated by undated and dated phylogenetic \rev{trees}.
An undated phylogeny will typically have branch lengths in units that reflect the overall number of molecular or morphological character changes \rev{that have occurred between the two edges of a branch (i.e., between the ancestral node and the younger node represented at the edges of this branch, respectively)}, while a dated tree will \rev{use} units of calendar time, such as years or millions of years.

%figure1
\ifnum\value{num}=10{
\begin{figure}
\centering
\includegraphics[width=\textwidth]{Cambridge-Elements/manuscript.R2/submitted_figs/figure1}
\input{Cambridge-Elements/manuscript.R2/submitted_figs/figure1}
\end{figure} }\else{}\fi

Inferring time calibrated trees is often achieved \rev{by} jointly estimating the topology and node ages.
In performing this analysis, researchers usually assume a tripartite model of evolution: one model that describes the accumulation of differences in character data, \rev{a second} that describes the distribution of evolutionary rates across the tree, and a \rev{third} model describing the distribution of speciation events (node ages) across the tree \citep{Thorne1998,Kishino2001,Yang2006,Drummond2006}.
This tripartite approach is a product of the history of phylogenetic model development and reflects the way in which researchers have traditionally tried to break down the problem of estimating evolutionary time from phylogenetic character data.
While the tripartite model may sound complex, it enables researchers to treat each component as a discrete inferential module and provides them with the flexibility to combine different models that best suit their data.
Understanding the tripartite framework is therefore useful for tracing the history of model development, making informed parameter choices, interpreting your results and diagnosing problems with your analysis.

\rev{Within macroevolution and evolutionary biology, the tripartite framework has typically been applied to infer dated trees  representing relationships among living species.
Recent technical and theoretical advances have allowed the tripartite framework to be applied to trees that also include extinct representatives, i.e., fossil species \citep{Stadler2010,Ronquist2012a,Heath2014,Gavryushkina2014,Zhang2016,Gavryushkina2017}.
This means the framework can be applied to entirely extinct clades, or other datasets for which we rely on morphology, rather than molecular data, to inform phylogenetic inference.
%It was previously necessary to infer tree topology and times in sequential separate analyses in paleobiology \citep{bapst2017b}, which has some statistical disadvantages, in particular, how uncertainty is reflected in the results.
The tripartite model has been used to infer trees, times and evolutionary rates among Cenozoic canids \citep{Slater2015}, crown birds and their Mesozoic relatives \citep{Lee2014}, Paleozoic echinoderms \citep{Wright2017b,WrightToom2017}, Cambrian trilobites \citep{Paterson2019}, and Cambrian Cinctans \ifnum\value{num}=10 {(Wagner, Wright and Wright in prep.)}\else {(see Wagner, Wright and Wright in this issue)}\fi.}
	
We describe the components of the tripartite model in more detail and the processes they aim to capture.
We \rev{then explain} how to perform this analysis \rev{with} Bayesian methods and highlight some of the advantages of using this statistical framework.
Finally, we discuss how different aspects of the tripartite model can be linked and how this can be used to test hypotheses in paleobiology.


%\rev{TODO Reviewer 1: One thing I thought might help ?sell? the paper to an phylogenetically unfamiliar audience of paleontologists would be to highlight more empirical case studies mostly or entirely comprised of fossil data (to help point readers to examples on groups having fossil records like the one they know best). That said, I wouldn?t necessarily advocate any additional section(s) be added to compensate--just a thought.}

\section{A brief introduction to Bayesian inference in phylogenetics}

%\rev{TODO watch out for redundancy in this section.}

In this review, we focus on divergence time estimation using Bayesian methods, which incorporate prior information and researcher intuition about parameters in our model.
Unlike some other \rev{approaches}, Bayesian methods estimate a sample of phylogenetic trees \rev{as well as a sample of} values for the parameters of the underlying phylogenetic model.
We can think of Bayesian inference as having three important components: the model likelihood, the prior, and the posterior.

We will be discussing these methods in a Bayesian context for a few reasons.
Perhaps the most important is that Bayesian methods estimate a sample of plausible parameter values under a model.
A Bayesian method inherently provides an indication of the uncertainty associated with any inferred model parameter.
Since we are unlikely to be able to observe the true parameter values for an event that occurred millions of years in the past, it is prudent to consider possible ranges for parameters in our model, \rev{within which the true parameter is likely to be}.
Bayesian methods also allow researchers to constrain the values an individual parameter can take.
This is a desirable property because we may have prior information from studies conducted by other \rev{researchers} about the numerical value of a parameter.
In this way, Bayesian inference provides an intuitive approach to accommodating uncertainty in other evolutionary and sampling parameters, and incorporating our existing knowledge of parameter values.
On a practical level, much of the widely-used divergence time estimation software has also been written in a Bayesian context.

%\rw{LH said she didn't think of divergence time estimation and time scaling as interchangeable but I actually do. Now that you've eliminated the term time scaling maybe this doesn't matter?}
%\aw{The more I think about it, the more I don't. I think if we say Bayesian time-scaling, I think of that as interchangeable with divergence time estimation. But coming from a molecular perspective, I also think of things like r8s (which I guess is sort of like some of the post-hoc time scalers you see in paleo) that are really philosophically different than what we're doing here.}
%\rw{Maybe we can leave this until a reviewer/someone else brings it up.}
%aw{Yes, I don't think this is crucial. We can say dated and call it good.}

\subsection{The model likelihood}

We often think of statistical words in colloquial terms.
For instance, we may think of ``likelihood" in our daily life as an event being likely or unlikely.
This is different \rev{from} statistics, when we calculate the model likelihood, or probability, of the observed data given a particular model.
A model is a mathematical description of a phenomenon.
Models are made up of parameters, which are thought to represent key factors of that phenomenon.
The relationship between parameters is described through mathematical expressions.
Many parameters of a model are treated as \textit{random variables}.
A random variable has an unknown value, \rev{for which candidate values will be tested as the inference of the given parameters proceeds}.
Bayesian analyses typically sample large numbers of solutions that explain how the data \rev{may have been} generated \rev{under the specified} model, with each sample appearing in proportion to its probability.
In the tripartite model for divergence time estimation, all parts of the model (substitution model, clock model and tree model) will be represented in the likelihood, as well as in the prior (Fig. \ref{fig:bayes}).

%figure2
\ifnum\value{num}=10{
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{Cambridge-Elements/manuscript.R2/submitted_figs/figure2}
\input{Cambridge-Elements/manuscript.R2/submitted_figs/figure2}
\end{figure} }\else{}\fi

\subsection{The prior}

%\rw{To do: as per DB's suggestion look into Alfaro and Holder's 2006 perspective on priors.}

%Bayesian methods incorporate researchers' prior knowledge and beliefs about the values a parameter may take through the use of priors.
%A prior distribution should reflect the belief or knowledge a researcher has about the value of a parameter.
A prior specifies a probability distribution from which the value of a particular parameter may be drawn.
Importantly, the value of a parameter can fall outside the prior distribution.
Priors can be enforced with varying degrees of strength.
If the data strongly support a value for a parameter that is in conflict with the prior specified, that value can still be supported if the prior is not strongly enforced.
Priors can also be chosen to offer maximal flexibility in the potential values for the parameter.
For example, a weak intuition about the value of a parameter can be incorporated via a vague prior.
In biology, it is fairly common to \rev{use} distributions such as the Gamma or Exponential \rev{as priors}, which can be very flexible depending on the centrality and/or shape parameters.
\rev{An example of the flexibility that can be achieved using alternative priors is shown in Fig. \ref{fig:distn}, in the context of the clock model.}
\rev{Because reliable information with which researchers can inform prior choice is often unavailable, this flexibility is  considered desirable \citep{brandley2006}.}

Sometimes, the distinction between what we call a model and the prior can be difficult to see (See Box \rev{`The likelihood, the prior and the posterior'} for more information).
By constraining the values a parameter can take, it is possible to steer estimation towards or away from certain sets of values, without changing what facets of the generating process are being modeled.
The priors, therefore, are part of a model, as they can lead to the parameters of that model taking on different values.

\subsection{The posterior}

The posterior is the outcome of a Bayesian analysis and includes a distribution of plausible \rev{values} for all of the  parameters \rev{specified} in our models, including the \rev{tree} topology and divergence times.
This component effectively combines the information from the prior with the likelihood. 
\rev{Fig. \ref{fig:bayes} provides a visual guide of how the prior and the likelihood come together to obtain the posterior.}
\rev{We cannot easily compute the posterior probability due to the relative complexity of phylogenetic models.}
\rev{The posterior is typically generated through what is referred to as Markov Chain Monte Carlo (MCMC) sampling. Under this algorithm, values for parameters are proposed, and the likelihood of the data under this model is scored.
Then, the model parameters are changed, and the data are re-scored under this new model. Generally, if the new parameter is an improvement, it is kept, and used as the seed for the next set of changes.
MCMC does not track what values have already been scored, therefore a parameter that is a good fit may be returned to multiple times.}

Values for each parameter will appear in the posterior distribution in proportion to how probable they are, given our model and priors.
The highest point or points of the distribution represent the most probable parameter estimates.
The variance of the posterior distribution for a given parameter reflects the uncertainty in that estimate.
If the variance in our posterior distribution is relatively high, this reflects lots of uncertainty in our parameter estimate.
Conversely, if the variance is relatively low \rev{the uncertainty in our estimate is low}.
Note that low uncertainty does not necessarily mean a value is true, just that there is high support for it given the data and model.
\rev{In other words, even though the precision with which the parameter value has been estimated is high (low uncertainty, small variance), this does not imply the inference has also been accurate. A value could be estimated with low uncertainty but actually be very far from the true value. High precision does not guarantee high accuracy.}
Similarly, high variance or uncertainty in the posterior does not necessarily mean that the model is incorrect or that the analysis \rev{is} bad. It simply means that there is limited information in our data.
It is also possible to have more than one peak in your posterior sample.
This indicates that multiple solutions are feasible given the model and the data.

From the posterior distribution of many standard model parameters (e.g., rate parameters) we can construct credible intervals, which are the Bayesian \rev{analog to} confidence intervals.
We typically use the 95\% highest posterior density (HDP) interval, which is the spread of posterior values that contains 95\% of the posterior.
The upper and lower limits of the of 95\% HPD are \rev{an} intuitive way of communicating the uncertainty associated with parameters such as rates or node ages.
Summarizing a posterior distribution of trees, \rev{however}, is altogether more tricky \citep{heled2013,OReilly2018}.
There are a variety of strategies for capturing the phylogenetic relationships that are best supported by the posterior, \rev{which aim to summarise the estimated trees}.
Support values for each node are typically based on the proportion of trees in the posterior in which that node also appears.
This is referred to as the posterior probability.

All approaches to producing summaries of the posterior have benefits and downsides \citep{heled2013}, especially when there is high uncertainty associated with the tree topology \citep{OReilly2018}.
We emphasise that the posterior of a Bayesian phylogenetic tree inference is really a distribution of trees and associated model parameters.
We should be careful to avoid placing too much confidence in any statistic or summary value from that distribution \citep{Warnock2017}.
Instead, it is important to understand the underlying models used to generate your tree, and how these may result in uncertainty given the data you have.

For more practical information about Bayesian phylogenetic inference we recommend \citet{nascimento2017}.

\section{A tripartite model for divergence time estimation}

A model provides us with an expression for calculating the probability of observing our data, given some underlying assumptions about the processes that generated the data.
Perhaps the most obvious thing we need to describe is the process of phylogenetic character evolution.
This is achieved \rev{by} using the \textit{substitution model}, which describes the probability of changing between different character states.
Substitution models are at the core of undated phylogenetic inference and essentially provide a measure of evolutionary distance.
We tend to measure evolutionary distance or branch lengths in an undated phylogeny as the \textit{number of expected substitutions per character}. We \rev{say} ``expected'' substitutions because models allow for hidden state changes, such that the number of changes could be larger than the number we observe from our data.
As noted above, phylogenetic characters do not contain information about absolute time. Evolutionary distances estimated using the substitution model actually represent a product of rate and time.
Ultimately, \rev{for a dated phylogeny}, we need to be able to estimate the substitution rate in \textit{expected substitutions per character per calendar unit time}.

To extract information about rates and times from phylogenetic character data we need a modeling framework that describes the  relationship between these variables, in addition to the substitution model.
This is achieved with the addition of the two key model components required to date a phylogeny: the \textit{clock model} and the \textit{tree model}.
The clock model describes how the substitution rate varies (or does not) across the tree.
The tree model describes the process of speciation, extinction, and lineage sampling that generated the tree.
To tease apart rate and time, we either need to know the average substitution rate or we need to calibrate the substitution rate using temporal information from elsewhere.
For macroevolutionary timescales, calibration information typically comes from fossil sampling times or the age of biogeographic events, information incorporated into the tree model.
The tripartite approach to divergence time estimation is a hierarchical Bayesian model, which means it links together different sub-models (i.e., the substitution, clock and tree models); see Box `Hierarchical Models'.

Note that rate and time are often semi-identifiable, meaning that multiple combinations of parameters can potentially generate the same probability of the observed data.
In this case, we may be unable to identify, or distinguish, the true parameter values.
In practice, this means we need to put strong prior information on the average substitution rate \rev{or} speciation times \citep{dosReis2013,dosReis2016}.
%A consequence of this that the results will be very sensitive to these priors.
\rev{Consequently, the results will be very sensitive to these priors, so it is very} important for biologists and paleobiologists to understand each of the component pieces in order to make good parameter choices.

\section{Substitution models}

The first component of the tripartite model is the substitution model.
The substitution model, sometimes called the site model, describes how phylogenetic characters in the dataset evolve.
These models are called substitution models because they were initially written to describe nucleotide changes.
These models describe how character change accumulates over time, leading to the observed phylogenetic data.
In the context of divergence time estimation, phylogenetic data are typically either molecular or morphological data, \rev{although analyses that integrate both types of data have also been conducted \citep{Ronquist2012a,schrago2013,wood2013,Gavryushkina2017}}.
While molecular and morphological data have very different properties, as will be discussed below, similar methods have historically been used to infer phylogenies from them.

Most data used in phylogenetic estimation has been discrete data.
Discrete data can be broken into non-overlapping categories.
For example, nucleotide sequence data can be clearly separated into four states: adenine, cytosine, guanine, and thymine.
Morphological characters are often divided into discrete states \citep{de1985ontogenetic}.
Most simply, these may correspond to an absence state (usually coded as `0') and a presence state (usually coded as `1') \citep{watrous1981}.
They may also correspond to more complex character diagnoses.

There are many models to describe how molecular sequence data evolve over time \citep{Jukes1969, Kimura1980, Felsenstein1981, Hasegawa1985, Tavare1986}.
Nucleotide data tend to have well-defined and discrete properties.
This allows a range of assumptions to be made about what changes we are likely to see over evolutionary time.
In most common \rev{nucleotide} substitution models, the probability of observing a change from one character state to another is taken to be the product of the \textit{exchangeability} between two nucleotides at \textit{equilibrium frequency} of the starting nucleotide (i.e., the nucleotide that exists in the sequence, \rev{which} will be substituted for \rev{the other}).
The exchangeabilities refer to the probability of seeing a change from one particular state to another.
These are often based on biochemical features of the nucleotide base.
For example, it is unlikely to see a purine (two-ringed nucleotides, adenine and guanine) substituted for a pyrimidine (one-ringed bases, cytosine and thymine).
This is \rev{due to biochemical properties} --- we are less likely to observe large changes, such as gaining a second ring of carbons on a structure, than smaller ones.
Equilibrium frequencies refer to the frequency that we would see each of our character states if we allowed the evolutionary process to run infinitely long (i.e., \rev{until it reaches the equilibrium}).
This is based on simple statistics: even if it is easy to change from one nucleotide to another, if the starting nucleotide is rare, that change will be seldom observed.
It may be easy to transition from an adenine to a guanine but, if we have no adenines in our dataset, we are unlikely to observe this change over time.

Making different combinations of assumptions has yielded a panoply of molecular models.
The simplest model of sequence evolution, the Jukes-Cantor model \citep{Jukes1969}, assumes only one parameter: the rate of evolution.
The exchangeabilities of this model are equal between all states.
The equilibrium frequencies are also assumed to be equal.
Therefore, under this model, you are as likely to observe a change that adds a second carbon ring to a pyrimidine as you are to observe changes from pyrimidines to other pyrimidines.
On the opposite end of the spectrum, the general time reversible model (GTR) \citep{Tavare1986} allows for six different exchangeabilities, and for each molecular character to have its own equilibrium frequency, illustrated in Fig. \ref{fig:Q}.
This is a more complex model, but it is often supported as being the correct one for many datasets \citep{abadi2019}.
\rev{Molecular} characters are typically assumed to evolve approximately neutrally, which means we can use relatively straightforward models of evolution.

Bayesian phylogenetics using morphological characters have historically used a more restricted set of models than analyses of molecular data.
While we may be able to divide a \rev{discrete} morphological character into multiple states, we may not be able to easily describe how states can transition from one to another over evolutionary time.
\rev{For instance,} molecular models assume that the biochemical properties of an adenine are the same today as they were in the past, and
that all adenines are the same in different locations in the dataset.
What are the properties of an absent \rev{morphological} character?
Does a change from \rev{state} `0' to `1' at character `1' imply the same magnitude of changes as the same change \rev{of states} at character `5'?
The lack of consistent meanings to character states has limited the assumptions that can be made about the process that generated morphological data.
Due to the limited number of morphological models available, model testing has not become common in morphological phylogenetics yet (though see an example of empirical model fitting in \cite*{bapst2017} and \ifnum\value{num}=10 {Wagner, Wright and Wright in (prep.)}\else {(in Wagner, Wright and Wright in this volume)}\fi),
and understanding the role of the morphological model in divergence time estimation is an active area of scholarship \citep{Klopfstein2019}.

%figure 3
\ifnum\value{num}=10{
\begin{figure}
\centering
\includegraphics[width=\textwidth]{Cambridge-Elements/manuscript.R2/submitted_figs/figure3}
\input{Cambridge-Elements/manuscript.R2/submitted_figs/figure3}
\end{figure} }\else{}\fi

Because of the lack of common meanings between morphological character states, those working with morphological characters have largely been confined to working with the Mk model \citep{Lewis2001} \rev{for discrete character evolution}.
This model is a translation of the Jukes-Cantor model \citep{Jukes1969} of sequence evolution to morphological characters, also shown in Fig. \ref{fig:Q}.
Therefore, it makes the same assumptions about the generating process: that exchangeabilities are the same among all \rev{character} states, and that all states have equal equilibrium character frequencies.
This is a fairly restrictive model but, in a Bayesian context, some assumptions can be relaxed, allowing the user to make a variety of assumptions about the evolution of morphological data \citep{Nylander2004, Wright2016}.
For a more detailed review of these methods, see \citep{Wright2019}.
\rev{In addition, continuous} morphological characters have \rev{recently been introduced} in phylogenetic inference \citep{goloboff2006, parins2017} and divergence time estimation \citep{AlvarezC2019}.
\rev{The evolution of these continuous characters can be modelled under} processes \rev{like} Brownian motion \rev{ \citep{Felsenstein1973a,Felsenstein1985a,gingerich1993}, Ornstein-Uhlenbeck \citep{Hansen1997,butler2004,beaulieu2012} or L\'evy processes \citep{Landis2013},} which allow for changes to accumulate continuously along a branch.

Discrete models are often adapted to take into account that characters (nucleotide or morphological) will evolve at different rates. Following \citet{Yang1994a}, most researchers have modeled among-character rate variation (ACRV) as being distributed according to a Gamma distribution.
A Gamma distribution can be manipulated to take a wide range of shapes.
This distribution \rev{is then discretized into different categories (commonly four, but more categories are possible)}
and the median rate of each category is used as the rate of evolution for that category.
This allows different sites to evolve according to different evolutionary rates, thereby correcting for different rates across sites.
This practice is common for both molecular and morphological data, though some studies have indicated that lognormal-distributed ACRV may be more appropriate for morphology \citep{wagner2011, Harrison2015}.
In particular, non-variable or parsimony-uninformative characters are usually not collected by morphologists and the lognormal distribution potentially provides a better fit for datasets that do not include a zero rate category.
\rev{Not including these invariant characters is known to inflate rates of character change along branches, and must be corrected for in phylogenetic analysis \citep{Lewis2001,leache2015}.}

\section{Clock models}
Both the clock and tree models are required to tease apart rate and time, \rev{as well as} to transform branches in units of time.
The function of the clock model is to describe the way the rate of character change varies, or does not vary, across the tree.
Individual models make different assumptions about how rate variation is distributed among branches.
These range from  every branch having the same rate of evolution to every branch having its own rate.
Each of these models implies specific evolutionary dynamics.
Below, we review some common clock models, which can apply to molecular or morphological data.

\subsubsection{Strict Clock}
Under the strict (or global) clock model, we assume that the rate of character change is constant across time and that the same rate applies to all branches in the tree \citep{Zuckerkandl1962, Zuckerkandl1965EvolutionaryDivergenceConvergence}.
This model adds one parameter to the overall model, describing the conversion between the rate of character change  and absolute time.
\rev{Different values for this conversion are typically still sampled via MCMC in Bayesian analysis.}

\subsubsection{Uncorrelated Clock}
\rev{Most clades, however,} do have variation in the rate of evolution over time.
A wide variety of clock models have been developed to describe how this variation manifests.
One common family of clock models is the uncorrelated relaxed clock model.
`Relaxed' refers to the clocks not being strict: any model that is relaxed will allow rate variation across the tree \citep{Drummond2006, Drummond2007}.
`Uncorrelated' means that the rate of evolution on a particular branch is not dependent on the rates of evolution of its neighbors or ancestor.
In this family of models, rates are typically assumed to be drawn from some distribution;
the uncorrelated lognormal clock (UCLN) \rev{model being the most commonly used}.
Under this model, the rate of any particular branch is assumed to be drawn from a lognormal \rev{distribution indepedently of other branches} (\rev{see an example in Fig. \ref{fig:distn})}.
The lognormal is a popular distribution in this type of analysis, as it implies most branches will have low, but typically non-zero, rates of evolution.
Because each branch has an independent draw from this distribution, meaning that the rate of a particular branch may be very different from its neighbors.
The parameters of the lognormal distribution can be fixed, or can be estimated themselves (i.e., are hyperparameters).
\rev{Nevertheless}, other distributions, such as the \rev{exponential} distribution, \rev{can also be used in these type of uncorrelated clock analyses}.
An \rev{exponential} distribution, as seen in Fig. \ref{fig:distn}, implies some branch rates are very close to zero.

%figure 4
\ifnum\value{num}=10{
\begin{figure}
\centering
\includegraphics[width=\textwidth]{Cambridge-Elements/manuscript.R2/submitted_figs/figure4}
\input{Cambridge-Elements/manuscript.R2/submitted_figs/figure4}
\end{figure} }\else{}\fi


\subsubsection{Autocorrelated Clock}
The idea of %rates being independent draws not dependent on the rates of the ancestor
a lineage's rate of evolution being independent of its ancestor's rate may strike some as odd.
Much of the literature on clock models is \rev{focused on} molecular data and molecular clocks.
Molecular clocks are influenced by a variety of factors, such as generation times, population sizes, and metabolic rates \citep{bromham1996, gaut1992,thomas2006,bromham2015}.
Morphological clocks are potentially impacted by the same variables\rev{, as well as other factors, such as developmental constraint \citep{Ho2014c}.} %todo need to find a citation for this
It would be reasonable, then, to expect that close relatives have similar evolutionary rates if they share these traits.

In autocorrelated rate models, the rate of a descendent branch is drawn from a probability distribution \citep{Aris-Brosou2002} centered on the rate of the ancestor's branch.
Different distributions can be assumed to allow the descendent's rate to be more different, or to force it to be more similar.


Autocorrelated clock models can also be continuous.
A continuous autocorrelated clock model assumes that, again, the distribution from which the rate of a descendant is drawn is centered on the rate of evolution of the ancestor.
Under these models, \rev{however,} the variance is typically proportional to the the length of the branch.
More sophisticated assumptions can be made under these continuous \rev{autocorrelated} relaxed clock models, such as the variance \rev{in rates} evolving across the tree \citep{Thorne1998, Kishino2001, Thorne2002, Aris-Brosou2002, Aris-Brosou2003}.

\subsubsection{Local Clocks}

Random local clocks behave in some ways like a strict clock, and in some ways like a relaxed clock.
A random local clock allows a subtree to have its own rate of evolution \citep{yoder2000}.
The branch subtending the subtree is the position of the shift between one clock rate and a new clock rate.
Generally, the new clock rate applies to the whole subtree, without relaxation.
The number of local clocks can vary between zero (one strict clock) to the number of branches on the tree (a fully relaxed clock).
Both the number of clocks that describe the tree and the location of the shifts from one clock to another are sampled during the MCMC in implementations of this model \citep{Drummond2010}.
\rev{MCMC variants that allow different numbers of parameters in different parts of the tree are called `reversible jump MCMC'.}


\subsubsection{Other Models of Evolutionary Rate Variation}

As \rev{described} above, breaking up the branches of a tree into separate rate classes can be accomplished in many ways.
Some have more straightforward biological interpretations, some have less.
Another approach is to use a mixture model.
Mixture models assume that there is substructure in a population of data.
In this case, our population of data are branches that evolve under different rates.
While the biological causes \rev{for those rates being different may not be the same}, branches evolving under similar rates can be modeled together.
Under a mixture model, the branches can be broken up in to \textit{n} categories.
\rev{In the case that a strict clock is favored}, \textit{n} will be one category, or it can be many more \rev{under other circumstances}.

Mixture models may be finite or infinite.
In a finite mixture model, the number of different rates is specified \textit{a priori}.
In this case, while there is a defined number of categories, which branches belong to which categories is \rev{something that needs to be estimated}.
On the other hand, a mixture model may be infinite.
In this case, the researcher does not specify a number of categories \textit{a priori}, \rev{this} is estimated during the phylogenetic \rev{inference} \citep{Heath2012a}.
In these models, a Dirichlet Process Prior \rev{(DPP)} is used to sample both the number of categories, the average rate for each category, and which branches belong to \rev{each} category.
A DPP can be more concentrated (assumes fewer rate categories) or more diffuse (assuming more categories).
Therefore, without assuming an explicit biological mechanism, they can be compatible with a number of biological scenarios.

\section{Tree models for time-calibrated tree inference}

%Think about adding an explaining about rooting

Tree models incorporate assumptions about the tree generating processes and provide us with an expression for describing the probability of observing a given time-calibrated tree (see Fig. \ref{fig:bayes}). This allows us to obtain a distribution containing the most likely trees, in terms of tree topology and branch durations, separate to any information we gain from the \rev{molecular or morphological character} data.
They also provide a framework for incorporating temporal evidence into our analyses --- that is, we use the tree model to propose a plausible range of ages for the nodes in our phylogeny.
In contrast to the substitution and clock models, only the tree model incorporates age information. %fossil
This information is used \rev{to} calibrate the substitution rate in combination with the substitution and clock model components.

Approaches to calibration can be placed into two useful categories: \textit{node-dating} and \textit{tip-dating}.
These broadly reflect major differences in how age information is combined with or incorporated into the tree model.
Briefly, node-dating assumes that our tree represents the relationships between living (extant) species only, and we constrain the ages of internal nodes using information from the geological record, without directly considering extinct or fossil samples as being part of the tree.
In contrast, tip-dating directly considers fossil samples as part of the tree.
In this section we provide an overview of popular tree models and describe how they are used in both node- or tip-dating scenarios.

The tree model is often referred to as the tree prior, and in combination with the calibration information, researchers often talk about the resulting prior distribution on node ages.
Some of the inconsistency in terminology can be attributed to the history of different models used for phylogenetic dating and whether we consider age information used during inference (e.g., fossil sampling times) as data.
Under the node-dating approach, fossil sampling times are used to constrain the age of a node.
In this framework, they are not data \rev{because} the generating process is not explicitly modeled.
Instead, the \rev{fossil times} are used to bound the age of a node.
Alternatively, if we model the process of fossil recovery explicitly, it becomes clear that the fossil ages are actually data, in addition to the morphological characters.
The terms process- and prior-based have also been used to distinguish between approaches that explicitly model the  process that generated the temporal evidence used in our analysis and those that \rev{do} not \citep{Landis2016}.
Here, we use the term tree model to refer to all the models that underlie these different approaches.
\rev{Tree models are} a large and important family of models used in Bayesian divergence time inference.
The tree model and/or the calibration information combined with the tree model can have a major impact on Bayesian estimates of node ages using both node- and tip-dating \citep[e.g.,][]{Ho2009,OReilly2015,Warnock2015,matzke2016,Matschiner2017}.

\subsubsection{Models of speciation, extinction and sampling}

The most intuitive models are those that capture the processes we believe gave rise to our data and include parameters with tangible, biological meaning.
An advantage of process-based tree models is that they can provide a better description of our data and also allow us to quantify other key parameters of interest, such as speciation (birth) and extinction (death) rates, in addition to the tree topology and divergence times.
The most widely used tree models in macroevolution are birth-death process models, which refer to a huge family of models, at the heart of which are the speciation and extinction processes \rev{(together, known as diversification processes)}.

The simplest model, the pure-birth model, assumes speciation is constant over time, that we have no extinction, and that we sample a representative of every individual lineage \citep{Yule1925}.
Under a pure-birth model with speciation rate $\lambda$, a single lineage splits in two with rate $\lambda$ (with the expected time between events $=1/\lambda$). Then, you have two lineages, each associated with rate $\lambda$, meaning you go from two to three lineages with rate 2$\lambda$. For any given number of lineages $n$, the rate of going from $n$ to $n+1$ will be $n\lambda$.
The most straightforward extension incorporates  extinction \citep{Kendall1948}.
Similar to the birth process, a single lineage goes extinct with rate $\mu$, meaning going from $n$ to $n-1$ lineages occurs with rate $n\mu$.

Restrictive assumptions, such as no extinction or constant rates of speciation may be reasonable in small and recent clades, but are not \rev{likely to occur} over long time intervals and for large groups.
In reality, we \rev{hardly} ever reach complete species sampling, \rev{especially in paleobiology}.
Some of the most important model developments in this area have therefore \rev{aimed} to relax the assumption of complete sampling, both at the present and in the past.
Sampling living species at the present and sampling either living or extinct species from the fossil record are typically treated as distinct processes.
In particular, it is useful to think of extant species as being sampled in the present ($t=0$) with a given probability $\rho$, which could be anywhere between zero and one, depending on the taxonomic scope of the study.
In contrast, we tend to model fossil recovery as a continuous process, with an associated rate parameter $\psi$. Like the birth and death processes, a new fossil is recovered with rate $n\psi$.

Tree models capture the underlying processes (speciation, extinction and sampling) that result in the \textit{complete} tree, including sampled and non-sampled lineages. But to calculate the probability of observing the  \textit{reconstructed} tree (the tree representing the relationships between sampled individuals only), we need to account for the fact that we only sample some subset of lineages.
For example, if we only sample living species, but assume both speciation and extinction have occurred, we need to use the expression for the \rev{probability} of observing our tree, given we only sample species at the present and none in the past \citep{Thompson1975,Gernhard2008, Stadler2009}.  Similarly, if we only sample a subset \rev{that does not include} all living species, we need to \rev{use} a model that incorporates incomplete extant species sampling \citep{Yang1997,Stadler2009}.
Figure \ref{fig:birth-death} shows examples of the complete versus \rev{the} reconstructed tree for different birth-death process models.

%figure 5
\ifnum\value{num}=10{
\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{Cambridge-Elements/manuscript.R2/submitted_figs/figure5}
\input{Cambridge-Elements/manuscript.R2/submitted_figs/figure5}
\end{figure} }\else{}\fi


The assumptions made by different tree models are important because they can result in very different distributions of plausible trees.
Different combinations of the speciation, extinction and sampling parameters give rise on average to different tree shapes, which determine the most probable waiting times between ancestor and descendent nodes
in the reconstructed tree.
For example, a reconstructed tree representing the relationships among a set of living individuals (i.e., the tree includes no extinct samples) is more likely to have shorter internal non-terminal branches and more evenly distributed speciation events if extinction is low relative to speciation.
Conversely, the reconstructed tree is more likely to have longer internal branches and on average older node ages if extinction is high.
More speciation events are missing from the reconstructed tree because extinct species are absent and there is a higher chance we have to go further back in time to find the speciation event linking any of our extant samples.

Note that we do not have to fix the speciation, extinction and sampling parameters.
Indeed, since different parameter combinations result in distinct distributions of trees and not all combinations are equally likely to result in the same tree shape, phylogenetic data  allows us to estimate these parameters if they are explicitly part of the tree model.
We typically use priors to constrain these parameters.

In the node-dating scenario, the tree represents the relationships between living samples and we typically use a tree model that includes extant species sampling only, excluding the process of fossil recovery.
Temporal information from the fossil record is instead incorporated through the use of \textit{node calibrations}.
For one or more internal nodes in our phylogeny we may have information about the age of the speciation event based on fossil or other geological evidence.
For example, for a given pair of lineages, the age of the first appearance of either one of these lineages represents a minimum (i.e., younger) bound for the age of the node separating them \citep{Parham2012}.
We can represent the uncertainty in the age of this node using a probability distribution. %LH: would it be an idea to discuss what are the common prob distributions considered (and why)?
This information is combined with the tree model to produce a distribution of trees that have branch lengths in units of absolute time.
This approach is somewhat less biologically intuitive than an explicit model of diversification and fossil recovery, since it does not consider the process that gave rise to the data (i.e., the fossil sampling times).
This leads to technical challenges combining node calibrations with the tree model and in interpreting the resulting distribution on node ages \citep{Heled2012,Warnock2015}.
It also requires assigning a fossil age to a fixed node in the extant species tree, ignoring the potential for phylogenetic uncertainty in the placement of the fossil species.

In tip-dating we consider extinct samples explicitly as being part of the tree and the temporal evidence used to constrain the age of the tree comes from the age of the extinct tips \citep{Ronquist2012a}.
To include fossil samples as part of the tree, we need to account for sampling through time and ideally we want to use a tree model that incorporates the process of fossil recovery.
The \textit{fossilized birth-death} (FBD) \textit{process} is an extension of the models described above that incorporates the fossil recovery process and provides an expression for the probability of observing a tree with samples recovered along internal branches \citep{Stadler2010,Heath2014,Gavryushkina2014}.
Extinct samples can either occur on terminal branches (i.e., tips) or along branches leading to other sampled descendants, referred to as \textit{sampled ancestors}.

When we \rev{consider} fossil samples as being part of the tree generating process, it becomes important to consider what each sample in our tree actually represents \citep{Hopkins2018}.
In the fossil record, a species will be represented by one or more fossil occurrences.
An occurrence could represent a single specimen or multiple specimens from the same locality.
Further, the age of each occurrence will be associated with an age range, reflecting imprecision in dating techniques, which can be referred to as the \textit{stratigraphic age} of an occurrence.
This uncertainty can be accounted for by placing a prior distribution on the age of the fossil, instead of treating the age as a known variable \citep{Drummond2016,BaridoSottani2019a}.
However, this is distinct from the observed duration of a species over geological time, beginning with the first (oldest) appearance of the species in the fossil record and terminating with the last (youngest) appearance, known as the \textit{stratigraphic range} of a species.
The FBD \textit{range} process is more appropriate for incorporating information about species through time \citep{Stadler2018}.
Birth-death process models have been extended in many ways, and of particular relevance to paleobiology, \rev{there} are models that relax the assumption of uniform diversification or species sampling \citep{Hoehna2011,Stadler2013b,Gavryushkina2014,Zhang2016,Kuehnert2016,BaridoSottani2018}.

\subsubsection{The uniform tree model}

Uniform tree models make the assumption that for a given set of taxa all possible trees are equally likely, and are available for both unconstrained and constrained (time-calibrated) tree inference \citep{Huelsenbeck2001a,Ronquist2012a}.
For timetrees this model is used for tip-dating rather than node-dating \citep{Ronquist2012a}.
Fossil species are treated as extinct tips and sampled as part of the tree.
Age information is incorporated through the fossil ages and an upper bound is applied to constrain the maximum age of the root.
Internal node ages are drawn from a uniform distribution, satisfying the age constraints imposed by the root and tip ages.
An advantage of this model is that it makes fewer explicit assumptions about the diversification, and the fossil and extant species sampling processes.
In this sense, the  uniform tree model is more straightforward, but has the disadvantage that it cannot be used to co-estimate diversification or sampling parameters.

In theory, given we have sufficient character data, the morphological data in combination with the terminal fossil ages should be informative about the substitution rate, and we should be able to recover the correct branch lengths, irrespective of the root constraint \citep{Ronquist2012a,Klopfstein2019}.
In reality, morphological datasets tend to be very small and this can result in the root constraint having a large impact on the results \citep{matzke2016}.
If the character data are not sufficiently informative about the substitution rate, we tend to observe that the older the root constraint, the older the node ages we recover, reflecting the uncertainty associated with the rate parameter.
Although uniform tree models are sometimes referred to as uninformative tree priors, this is somewhat misleading if we consider the influence of the root constraint and the potential impact of ignoring sampled ancestors \citep{Gavryushkina2014}.

\subsubsection{Coalescent tree models}
Another large family of tree models used to describe the generation of timetrees are coalescent models. 
These are typically used to model the evolution of genes within a population\rev{, though they are also used in phylogenetic and phylogenomic estimation \citep{liu2008a, song2012, mirarab2014}.}
In this context, the tree typically represents a succession of non-overlapping generations and each branching point represents a \textit{coalescence event}, which is the point at which two genes in a population last shared a common ancestor \citep{Kingman1982}.
In contrast to birth-death models, which are forwards-time processes, coalescent models are backwards-time processes.
Time to coalescence will be a function of population size over time --- the larger the population, the more likely you have to go further back to recover the ancestor of two individuals. %bother mentioning mutation rate? \aw{I think it's OK not to - this is important to sketch in generality, but I think likely to be a bit beyond the ken of most paleo folks}
Similarly to birth-death models, coalescent models have also undergone an enormous amount of development and provide flexible options for describing population growth \citep{Beerli2001, Drummond2005, Mashayekhi2019}. %For example we can relax the assumption of constant population size through time

Although coalescent models can incorporate extinct tips, we do not tend to use these directly to describe the evolution of species, but they can be important in estimating species trees and divergence times from genetic data. %individual gene trees.
Trees based on individual genes can be quite different from the true underlying species history.
This occurs when coalescence events between individuals belonging to populations of different species are older than the speciation event.
This scenario is known as \textit{incomplete lineage sorting} and can lead to a mismatch between gene and species trees.
Following speciation, it takes time for genes to become sorted across distinct species populations, such that gene trees  eventually reflect the species tree \citep{Maddison2006}.
This interval of time depends on several factors, including population size, and can be extremely long (e.g., populations of humans and chimpanzees still share genetic differences).
However, the mismatch between gene and species trees can actually persist forever if genes do not become sorted before subsequent speciation events \citep{Xu2016}.
Mismatch is most likely to occur when the branches separating speciation events are very short, irrespective of the  \rev{time since speciation (i.e., whether the events are geological recent or not)}. This scenario creates a huge challenge \rev{when} inferring the species tree.
Discerning the relationships between the major lineages of birds is a good example of this issue --- these events happened almost 66 myr, but the internal branches in this portion of the tree are extremely short. As a consequence, different gene trees produce conflicting topologies \citep{Jarvis2014}.
In the face of considerable conflict, identifying a consensus is not straightforward.
%In particularly problematic cases, we cannot simply get around this issue by concatenating genes.
One solution is to explicitly model the evolution of genes, in combination with the speciation process, under the \textit{multi-species coalescent model} \citep{Heled2010}.
In this framework, we can apply a separate coalescent model to each gene in our dataset, and we model the speciation process using a birth-death model.
We effectively assume that the gene trees are embedded within the species tree.
We can use the FBD model for the species tree, meaning we can also incorporate extinct species, with or without molecular and/or morphological data \citep{ogilvie2018}.
If we also have morphological characters and assume that morphology follows the species tree history, rather than being described by a coalescent model, we can use the species tree model for the \rev{morphology}.
This is a good example of the hierarchical and extendable nature of phylogenetic tree models, but also showcases a level of complexity that will not always be necessary \rev{to recover the correct tree}.

%hybridization

\subsubsection{Biogeographic dating}

Temporal evidence for the age of a node can also come from the geological events linked to speciation \citep{Ho2015,deBaets2016}.
For example, the current biogeographic distribution of living taxa may indicate that species divergence is tied to specific tectonic events that likely resulted in genetic isolation, such as island formation or the break up of continents that previously existed  in Earth's history.
This approach is especially useful for taxonomic groups with a sparse or non-existent fossil record.
Age information can be incorporated using a node dating approach, where the timing of biogeographic events are used to inform the calibration distributions, and the tree generating process can be described using a birth-death model.
One challenge to this approach is establishing a definitive causal link between tectonic and speciation processes, especially if events happened a long time ago (e.g.,\ the breakup of Gondwana) \citep{deBaets2016}.

More recently, process-based models have been introduced for biogeographic dating and tree inference \citep{Landis2016,Landis2019}.
This approach is conceptually similar to birth-death models that incorporate the fossil recovery process in that they explicitly incorporate a model of the evolution of biogeography.
In this setup, we have information about the distribution of living species at the tips of our tree, and a model of tectonic history that incorporates age information.
Species are allowed to disperse between areas with a given rate, which can depend on the current state of the tectonic configuration.
For example, a species cannot disperse to an island before the island exists.
Similarly, the potential for dispersal between two continents will depend on their connectivity.
Thus, the probability of the tree and divergence times is linked to the biogeographic model.
An advantage of this approach is that we do not need to make fixed assumptions about the link between biogeographic scenarios and speciation.
Instead, we can use this approach to test among biogeographic hypotheses --- not all histories will be equally likely to have produced the current distribution of living species.
So far this approach has been used to date trees of extant species only, however, future extensions could potentially account for the biogeography of extinct and fossil samples.
In principle, we could even combine models of biogeographic processes with models of diversification and fossil recovery.

\section{Expanding the potential of the tripartite model within the Bayesian framework}

Bayesian priors incorporate our pre-existing knowledge about parameter values. %(see Box)
We tend to think about the role of priors as being restricted to  constraining the range of possible values a given parameter can take, e.g., the clock rate or speciation rate, or to express which values are most probable based on what we already known.
However, we can use priors to manipulate the parameter space in much more sophisticated ways than we are currently used to doing.
We can expand the range of assumptions we are able to make about the underlying biological processes and take advantage of Bayesian approaches to model testing.
The development of more flexible Bayesian software, such as \textsc{RevBayes} \citep{Hoehna2014b, Hoehna2016b} and BEAST2 \citep{BEAST2}, \rev{alongside resources for understanding the underlying models} \citep{Barido2018}, %note here we could also cite the tutorials associated with this PS short course
make complex inference much more accessible to everyday users.
Here, we provide examples, ranging from simple to complex.

A tripartite model enables nearly endless combinations of substitution, clock, and tree models to be assembled into a complete model.
For example, in molecular genetics, partitioning \rev{(defining subsets of the data)} by gene and applying an appropriate model of sequence evolution to each gene, is strongly supported as being important to inferring a correct phylogeny \citep{Brandley2005}.
Likewise, different models of morphological evolution can be \rev{used interchangeably}. %substituted
For example, the assumption made by the Mk model that a character is equally likely to change state as to reverse that state change may seem unrealistic.
In this case, a model that allows asymmetrical rates of change \citep{Ronquist2004} could be substituted.
 This \rev{alternative} model puts a prior on character state frequencies, allowing them to be unequal, which increases the probability of certain types of character change.
 For example, many changes are likely to be observed from a common character state to other states.
Character change asymmetry has recently been shown to affect divergence time estimation \rev{based on discrete character data \citep{Klopfstein2019}, as well as tree inference \citep{Wright2016}.}
If a researcher believes this to be the correct model for their data, it can be substituted for a traditional Mk model, without necessarily needing to alter the clock or tree models.

Depending on our parameters of interest, we can change the way our models are parameterized.
For example, we may be more interested in diversification ($d$) and turnover ($r$) than speciation ($\lambda$) and extinction ($\mu$).
If we use a birth-death process tree model, we cannot eliminate speciation and extinction from the calculation, but we can reparameterize our analyses, such that we can place priors directly on the diversification and turnover parameters and sample these during MCMC. We can recover the speciation and extinction rates via transformation \citep{Heath2014}.
The relationship between the parameters can be expressed simply as,
$$d = \lambda - \mu, \quad r = \frac{\mu}{\lambda} \quad \textrm{and} $$
$$\lambda = \frac{d}{(1-r)}, \quad \mu = \frac{rd}{(1 - r)}.$$

Although in principle we can recover diversification and turnover from estimates of speciation and extinction without reparameterizing the model, this would give us less control over our parameters of interest.
While this is a relatively straightforward example, this illustrates how parameters that are not explicitly part of the model can still be used to constrain the underlying model in our analysis.
For instance, if other biological or environmental variables %\edit{such as sea level}
can be linked to model parameters via transformation, we have the potential to take advantage of this additional data.

We can also manipulate the relationship between independent parameters within a model through the use of priors.
For example, we can link different parameters of the tree model in different ways.
The FBD skyline model can incorporate variation in the speciation, extinction and fossil recovery rates over time \citep{Gavryushkina2014,Zhang2016}.
By default, model parameters are treated as independent.
However, our prior assumption may be that parameters in adjacent time intervals, such as diversification rates, are more likely to be similar.
To incorporate this expectation, the rate of diversification in a time interval could be parameterized according to the rate of diversification in the previous time interval, much like the relationship between descendant branches under the autocorrelated \rev{relaxed} clock model.
In effect, this allows for distinct time intervals to have semi-independent model parameters.
Alternatively or in addition, if we have reason to believe that different model parameters are linked, we can also manipulate the priors to specify this expectation.
For instance, we may have reason to believe that rates of diversification are linked to the rate of fossil sampling \citep{Holland1995,Peters2005}.

However, we may very well believe that parameters in \textit{different} sub-components of the model are linked.
If we believed the rate of speciation to be related to the rate of character change,
this could be achieved by using a prior that specifies a distribution for one parameter, centered on the other.
For example, if we thought that periods of high speciation would correspond to periods with lots of character change, we could create an FBD skyline model in which the per-interval prior on speciation rate is linked to the average substitution rate during that interval.

Within a Bayesian framework, we can propose any model we would like, and use modeling tests to compare competing models, in which parameters are either linked or not.
Bayesian methods have a suite of well-developed statistical approaches for evaluating the fit of both the model and the priors to the data.
\rev{For instance,} Bayes Factors \citep{Xie2011} \rev{are} metrics \rev{that} describe the support for one model, and all its associated priors, over another model.
\rev{This approach} weighs the posterior evidence of two models against one another.
%Unlike some other types of model testing, methods can be used to compare non-nested or mixture models.
It is worth noting, however, that the Bayes Factor can only provide evidence in favor of one model.
It cannot tell a researcher if the model is adequate; that is, capturing important facets of the process of evolution.
Other methods, such as posterior predictive model assessment can be used to assess model adequacy \citep{Brown2009, Brown2014, Duchene2015, Hoehna2018}.
With these methods, it is important to consider what the data are.
Node calibration methods, for example do not truly incorporate fossils as data.
Instead, the fossils are used as priors to bound the age of nodes.
In this case, their placement is part of the model, and methods have been proposed to evaluate these priors with Bayes Factors \citep{Andujar2014}. %\edit{though the statistical incoherence associated with node dating makes it unclear whether this is appropriate}.
In the case of an FBD tree model, they are data, \rev{thus} Bayes Factor model fitting cannot be used to evaluate the placement of fossils.

Many of the more complex model and prior options we describe here have yet to be explored using paleobiological data, despite their increasing feasibility.
To extend the tripartite model, we must understand how it works under a variety of empirical conditions.
Much of what we know about both divergence time estimation and phylogenetic analysis comes from simulation studies and mathematical modeling.
While both of these are useful tools, it can be difficult to understand how the behavior of any particular method will stand up to empirical conditions.
Limited data sizes, biased missing data, and violations of model assumptions can all lead to unpredictable analytical behavior.
Therefore, it is critical for %researchers
empiricists and theoreticians to collaborate to understand the challenges faced by researchers at the forefront of collecting data, and improve our methods to meet them.

\rev{Here, we focused on the scenario in which we have both phylogenetic character data as well as temporal evidence of speciation, and where the goal is to estimate divergence times or to co-estimate divergence times and topology.
The inclusion of molecular or morphological characters requires both the substitution and clock model.
We cannot infer the topology without phylogenetic characters, however, in principle, the tree model could still be used to infer the divergence times for a tree topology obtained using other evidence.
For example, phylogenies based on taxonomic classification have been shown to be valuable in phylogenetic comparative analyses \citep{soul2015}.
In this context, the tree may not be fully resolved but the timing of key divergence events can still be estimated under the tree model, taking into account the uncertainty at unresolved nodes.
Similarly, since fossil sampling times are informative about the speciation, extinction and fossil recovery rates, the FBD \citep{Warnock2020} and related birth-death models \citep{Silvestro2014b} can be used to recover these parameters, even without any knowledge about the underlying phylogeny %if the phylogeny and divergence times cannot be recovered
.}

\section{Conclusions}

Bayesian divergence time estimation is commonly performed in a tripartite framework.
One model describes the process the researcher believes generated \rev{the} character data.
\rev{Another model} describes the manner in which the researcher believes rates of evolution are distributed across the tree.
The final model describes the extinction, speciation and sampling events that \rev{potentially} led to the observed tree.
Each of these components has its own parameters, which are believed to describe the process that generated the data.
\rev{Each component model's parameters can have priors too}, which describe the distribution of values we expect a parameter to take.

This framework enables nearly endless combinations of assumptions that a researcher can make about their data.
The goal of this review has been to explain some common assumptions, and what they mean.
It is by no means exhaustive.
There are more assumptions that could be made and modeled by researchers.
This tripartite framework can be improved by a close collaboration between geologists, organismal experts, and phylogenetic methods specialists.
We hope that, in explaining some of these common assumptions, researchers will feel empowered to look at their own data and see where methods can be improved, and to seek collaborations to create a new generation of process-driven methods. The challenge for both empirical researchers and method developers will be to identify important model violations, and to gauge the level of complexity \rev{required} to obtain reliable and meaningful results.

%\section{Acknowledgements}
